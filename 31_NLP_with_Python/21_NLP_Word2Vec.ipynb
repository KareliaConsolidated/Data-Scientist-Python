{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained word vectors using gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "wiki_embeddings = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32307 , -0.87616 ,  0.21977 ,  0.25268 ,  0.22976 ,  0.7388  ,\n",
       "       -0.37954 , -0.35307 , -0.84369 , -1.1113  , -0.30266 ,  0.33178 ,\n",
       "       -0.25113 ,  0.30448 , -0.077491, -0.89815 ,  0.092496, -1.1407  ,\n",
       "       -0.58324 ,  0.66869 , -0.23122 , -0.95855 ,  0.28262 , -0.078848,\n",
       "        0.75315 ,  0.26584 ,  0.3422  , -0.33949 ,  0.95608 ,  0.065641,\n",
       "        0.45747 ,  0.39835 ,  0.57965 ,  0.39267 , -0.21851 ,  0.58795 ,\n",
       "       -0.55999 ,  0.63368 , -0.043983, -0.68731 , -0.37841 ,  0.38026 ,\n",
       "        0.61641 , -0.88269 , -0.12346 , -0.37928 , -0.38318 ,  0.23868 ,\n",
       "        0.6685  , -0.43321 , -0.11065 ,  0.081723,  1.1569  ,  0.78958 ,\n",
       "       -0.21223 , -2.3211  , -0.67806 ,  0.44561 ,  0.65707 ,  0.1045  ,\n",
       "        0.46217 ,  0.19912 ,  0.25802 ,  0.057194,  0.53443 , -0.43133 ,\n",
       "       -0.34311 ,  0.59789 , -0.58417 ,  0.068995,  0.23944 , -0.85181 ,\n",
       "        0.30379 , -0.34177 , -0.25746 , -0.031101, -0.16285 ,  0.45169 ,\n",
       "       -0.91627 ,  0.64521 ,  0.73281 , -0.22752 ,  0.30226 ,  0.044801,\n",
       "       -0.83741 ,  0.55006 , -0.52506 , -1.7357  ,  0.4751  , -0.70487 ,\n",
       "        0.056939, -0.7132  ,  0.089623,  0.41394 , -1.3363  , -0.61915 ,\n",
       "       -0.33089 , -0.52881 ,  0.16483 , -0.98878 ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the word vector for \"King\"\n",
    "wiki_embeddings['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 0.7682329416275024),\n",
       " ('queen', 0.7507690787315369),\n",
       " ('son', 0.7020887732505798),\n",
       " ('brother', 0.6985775232315063),\n",
       " ('monarch', 0.6977890729904175),\n",
       " ('throne', 0.691999077796936),\n",
       " ('kingdom', 0.6811410188674927),\n",
       " ('father', 0.680202841758728),\n",
       " ('emperor', 0.6712858080863953),\n",
       " ('ii', 0.6676074266433716)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the words most similar to king based on the trained word vectors\n",
    "wiki_embeddings.most_similar('king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Our Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                                                                 text\n",
       "0   ham  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...\n",
       "1   ham                                                                        Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...\n",
       "3   ham                                                    U dun say so early hor... U c already then say...\n",
       "4   ham                                        Nah I don't think he goes to usf, he lives around here though"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "messages = pd.read_csv('Data/spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
    "messages.columns = ['label', 'text']\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[dun, say, so, early, hor, already, then, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, don, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  ...                                                                                           text_clean\n",
       "0   ham  ...  [go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...\n",
       "1   ham  ...                                                                          [ok, lar, joking, wif, oni]\n",
       "2  spam  ...  [free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...\n",
       "3   ham  ...                                                       [dun, say, so, early, hor, already, then, say]\n",
       "4   ham  ...                                [nah, don, think, he, goes, to, usf, he, lives, around, here, though]\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text_clean'], messages['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Word2Vec Model\n",
    "w2v_model = gensim.models.Word2Vec(X_train, size=100, window=5, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.47480250e-03,  4.89197150e-02,  1.55280884e-02, -2.07717642e-02,\n",
       "        5.98440170e-02, -5.40387034e-02,  5.42783029e-02, -6.58157840e-02,\n",
       "        4.86163497e-02, -2.23793392e-03,  1.41202435e-02, -3.01181525e-03,\n",
       "        8.25160742e-03, -1.04071731e-02,  7.79867470e-02,  3.36317793e-02,\n",
       "       -1.37883816e-02, -6.31777868e-02, -9.52171627e-03, -1.27347186e-02,\n",
       "        7.30414363e-03,  8.20679590e-02,  6.40482083e-03,  5.61638512e-02,\n",
       "       -3.11943237e-02, -6.12702873e-03, -3.26459147e-02, -4.28950004e-02,\n",
       "       -1.27214827e-02, -1.97663605e-02, -6.62363041e-03, -7.27722049e-03,\n",
       "       -2.99057811e-02,  2.16301661e-02, -3.43814380e-02, -5.42792045e-02,\n",
       "        2.81547755e-02,  3.78717780e-02,  9.45917293e-02,  8.04313049e-02,\n",
       "        1.86724905e-02,  8.53597943e-04, -5.35032600e-02,  1.25380047e-02,\n",
       "        5.62016852e-02, -9.18933600e-02, -3.17984000e-02, -3.71681042e-02,\n",
       "        2.63517397e-03, -3.34987007e-02,  1.12115443e-02,  8.96828771e-02,\n",
       "       -3.97659205e-05,  4.63693626e-02, -6.39875084e-02, -2.50612516e-02,\n",
       "        3.69046964e-02, -6.72178864e-02, -1.53378919e-02,  2.98513882e-02,\n",
       "        3.38975042e-02,  1.53278084e-02,  9.01198667e-03, -5.84152620e-03,\n",
       "       -1.43350114e-03,  3.23148258e-02,  3.96158099e-02, -2.30140481e-02,\n",
       "       -2.31862366e-02,  6.55095875e-02, -2.34455857e-02, -6.02412336e-02,\n",
       "        2.63014194e-02,  4.25355025e-02,  2.27591805e-02, -6.64490461e-02,\n",
       "       -2.38069706e-02, -6.23883270e-02, -3.10850125e-02, -2.61383299e-02,\n",
       "        2.23556347e-02,  1.31144943e-02,  4.32122722e-02, -5.23741730e-02,\n",
       "       -6.99861767e-03,  1.57195237e-02, -3.14731114e-02, -9.85746682e-02,\n",
       "        2.69585829e-02, -1.15662776e-02,  1.88782327e-02,  1.74512696e-02,\n",
       "       -6.33829758e-02, -3.98791544e-02,  4.17713001e-02,  4.47020382e-02,\n",
       "       -2.29668375e-02, -1.25015220e-02, -1.29788974e-02,  9.29738730e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the word vector for \"king\" base on our trained model\n",
    "w2v_model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('club', 0.9977988004684448),\n",
       " ('use', 0.9977649450302124),\n",
       " ('every', 0.9977463483810425),\n",
       " ('uk', 0.9977246522903442),\n",
       " ('us', 0.9977229237556458),\n",
       " ('wan', 0.9977207183837891),\n",
       " ('then', 0.9977165460586548),\n",
       " ('already', 0.9977091550827026),\n",
       " ('this', 0.9977082014083862),\n",
       " ('double', 0.9977070093154907)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"king\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
